---
title: "TISLR Data Analysis"
author: "Adam Stone, PhD"
date: '`r format(Sys.Date(), "%m-%d-%Y")`'
output:
  html_notebook:
    code_folding: hide
    highlight: tango
    theme: cosmo
    toc: yes
    toc_depth: 2
    toc_float: yes
---

```{r}
get_xy_timestamp <- function(z){

x <- read_lines(z) %>%
  as_tibble() %>%
  rowid_to_column("ID")

# pull out timestamp rows
timestamps <- x %>%
  filter(str_detect(value, "timestamp")) %>%
  separate(value, into = c("throw","timestamp"), sep = " = ") %>%
  separate(timestamp, into = c("one","two","sec"), sep = ":") %>%
  select(sec) %>%
  mutate(sec = as.numeric(sec))

# Find AOI coordinate rows
xys <- x %>%
  mutate(find = str_detect(value, "X\tY"))

# first vertex (2 rows after each "XY" line)
xys_row <- which(xys$find) + 2

xy1 <- x %>%
  filter(ID %in% xys_row) %>%
  separate(value, into = c("x1","y1"), sep = "\t") %>%
  select(-ID)

# opposite vertex (2 more rows down)
xys_row <- xys_row + 2

xy2 <- x %>%
  filter(ID %in% xys_row) %>%
  separate(value, into = c("x2","y2"), sep = "\t") %>%
  select(-ID)

# Now get average XY position per timestamp
xys <- cbind(timestamps, xy1, xy2) %>%
  mutate_all(as.numeric) %>%
  rowwise() %>%
  mutate(x = mean(x1,x2),
         y = mean(y1, y2)) %>%
  select(sec, x, y)
}
```

# Three Bears Data

## Introduction

Rain, I was confused by the low number of participants in each group...then realized only half the participants saw Three Bears Forward, right? The other half saw Three Bears Backwards? 
```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(openxlsx)
library(janitor)
library(skimr)
library(gganimate)
library(tsibble)

# Get Three Bears data
rawdata <- read.xlsx("Test1_Cindy_bears_FW_Examine for Spatial Referencing.xlsx") %>%
  clean_names() %>%
  rename(x = gaze_point_x_mc_spx,
         y = gaze_point_y_mc_spx,
         language = language_value,
         name = participant_name,
         group = group_value)

# Pull clean names (and handle Laura2 for Laura (missing stories))
cleannames <- read_csv("partnames.csv") %>%
  distinct() %>%
  rename(name = participant) %>%
  filter(name != "Laura2")

# Pull final group assignments
cleangroups <- read_csv("finaldataset.csv") %>%
  select(participant, maingroup) %>%
  rename(name = participant) %>%
  distinct()

# Join both to rawdata
data <- rawdata %>%
  left_join(cleannames, by = "name") %>%
  select(-name) %>%
  rename(name = new_participant) %>%
  filter(!is.na(name)) %>%
  left_join(cleangroups, by = "name") %>%
  select(-group)

# Let's find out who was NOT included in Three Bears
excluded <- read_csv("finaldataset.csv") %>%
  select(participant, maingroup, story, direction, eye_exclude) %>%
  filter(story == "Goldilocks" & direction == "forward") %>%
  rename(name = participant) %>%
  select(name, eye_exclude)

data <- data %>% left_join(excluded, by = "name") %>%
  filter(!eye_exclude) %>%
  filter(!is.na(eye_exclude)) %>%
  select(-c(eye_exclude, recording_name)) %>%
  mutate_at(vars(language, maingroup, name), as.factor)

data %>% distinct(name, maingroup) %>% count(maingroup)

skim(data)
```

Let's graph everything, first of all. 

```{r warning=FALSE}
data %>%
  ggplot(aes(x = gaze_point_index, y = y, color = maingroup, group = name)) + 
  geom_line() + 
  scale_y_reverse(limits = c(1080,0)) +
  theme_bw() +
  facet_wrap("name")
```

## Smoothing

We're adding smoothing with a moving average window size - 5. (y_ma5). Good for removing noise. We'll try using either and see where we go. 

Then we'll eliminate 30 samples from the start and end (that's 0.25 seconds on both sides). 

> The data were then smoothed with a standard moving average noise reduction algorithm (window size = 5 samples) which acts as a low-pass filter that reduces the influence of microsaccades, blinks, and large data gaps (based on Yarbus, 1967). 

```{r}

min_gaze_point_index <- data %>% 
  group_by(maingroup) %>%
  summarise(max = max(gaze_point_index)) %>%
  ungroup() %>%
  summarise(min(max)) %>%
  pull()

bookend <- 30

data <- data %>%
  as_tsibble(key = id(name), index = gaze_point_index) %>%
  group_by(maingroup, name) %>%
  mutate(y_ma5 = slide_dbl(y, ~ mean(., na.rm = T), .size = 5)) %>%
  as_tibble() %>%
  ungroup() %>%
  filter(gaze_point_index > bookend & gaze_point_index < min_gaze_point_index - bookend)

# data %>%
#   ggplot(aes(x = gaze_point_index, y = y_ma5, color = maingroup, group = name)) +
#   geom_line() + 
#   scale_y_reverse(limits = c(1200,0)) +
#   theme_bw() +
#   facet_wrap("name")
# 
# data %>%
#   ggplot(aes(x = gaze_point_index, y = y_ma10, color = maingroup, group = name)) +
#   geom_line() + 
#   scale_y_reverse(limits = c(1200,0)) +
#   theme_bw() +
#   facet_wrap("name")

data %>%
  filter(name == "Adam") %>%
  ungroup() %>%
  gather(key = "metric", value = "y_position", c(y, y_ma5)) %>%
  ggplot(aes(x = gaze_point_index, y = y_position, color = metric)) +
  geom_line() +
  facet_wrap("metric", nrow = 3) +
  scale_y_reverse(limits = c(1080,0)) +
  ggtitle("Adam")


data %>%
  filter(name == "JJ") %>%
  ungroup() %>%
  gather(key = "metric", value = "y_position", c(y, y_ma5)) %>%
  ggplot(aes(x = gaze_point_index, y = y_position, color = metric)) +
  geom_line() +
  facet_wrap("metric", nrow = 3) +
  scale_y_reverse(limits = c(1080,0)) +
  ggtitle("JJ")
```

Also curious about missing data points. This counts how many missing data points we have for each participant, at the three different measurements. Based on that, I probably should take out Lynnette, so much missing data there. We'll worry about that later. 

```{r}
data %>%
  group_by(name, maingroup) %>%
  summarise_at(vars(y, y_ma5), funs(sum(is.na(.)))) %>%
  arrange(desc(y))

data %>%
  group_by(maingroup) %>%
  summarise_at(vars(y, y_ma5), funs(sum(is.na(.)))) %>%
  arrange(desc(y))
```

Playing with animation 

```{r}
averaged_groups <- data %>%
  group_by(maingroup, gaze_point_index) %>%
  summarise(x = mean(x, na.rm = T),
            y = mean(y_ma5, na.rm = T)) %>%
  filter(!is.na(y))
  

p <- ggplot(averaged_groups, aes(x = x, y = y, color = maingroup, group = maingroup)) +
  geom_point() +
  scale_x_continuous(limits = c(0,1440)) +
  scale_y_reverse(limits = c(1080,0))

p

anim <- p + 
  transition_time(gaze_point_index) +
  ggtitle("Gaze Point Index: {round(frame_time,0)}", subtitle = 'Frame {frame} of {nframes}') +
  shadow_wake(wake_length = 0.1, alpha = 0.25)
  
#animate(anim, duration = 25.8)
```

## DeafEarly as Baseline

So I took group averages of each group's y-coordinates, and then established Deaf Early as the "baseline" by which all other groups are measured. I calculated the difference in y position between Deaf Early vs. Deaf Late, Deaf Early vs. Hearing Late, Deaf Early vs. Hearing Novice. 

The charts below show the y-coordinate differences. 
```{r}
# First, calculate the baseline
deafearly_baseline <- data %>%
  group_by(maingroup, gaze_point_index) %>%
  summarise(de_y = mean(y_ma5, na.rm = T)) %>%
  filter(maingroup == "DeafEarly") %>%
  ungroup() %>%
  select(-maingroup)

# Let's try...grouped averages first 
grouped_baselines <- data %>%
  filter(maingroup != "DeafEarly") %>%
  group_by(maingroup, gaze_point_index) %>%
  summarise(y = mean(y_ma5, na.rm = T)) %>%
  left_join(deafearly_baseline, by = "gaze_point_index") %>%
  mutate(diff_y = y - de_y)

de_mean <- mean(deafearly_baseline$de_y, na.rm = T) * -1

grouped_baselines %>%
  ggplot(aes(x = gaze_point_index, y = diff_y, color = maingroup)) +
  geom_line() +
  scale_y_reverse(limits = c(1080 + de_mean, de_mean))

grouped_baselines %>%
  ggplot(aes(x = maingroup, y = diff_y, fill = maingroup)) +
  geom_violin() +
  geom_boxplot(width = 0.2, fill = "white") +
  scale_y_reverse(limits = c(1080 + de_mean, de_mean)) +
  geom_hline(yintercept = 0)

```

I'm doing to do this again, but use the Deaf Early baselinea against the *individual* gaze data, not the grouped gaze data. That also lets us do statistics.

```{r}
individual_baselines <- data %>%
  filter(maingroup != "DeafEarly") %>%
  left_join(deafearly_baseline, by = "gaze_point_index") %>%
  group_by(name, maingroup, gaze_point_index) %>%
  mutate(diff_y = y_ma5 - de_y)

individual_baselines %>%
  ggplot(aes(x = gaze_point_index, y = diff_y, color = maingroup, group = name)) + 
  geom_line() + 
  scale_y_reverse(limits = c(1080 + de_mean, de_mean)) +
  theme_bw() +
  facet_wrap("name")

individual_baselines %>%
  ggplot(aes(x = maingroup, y = diff_y, fill = maingroup)) +
  geom_violin() +
  geom_boxplot(width = 0.2, fill = "white") +
  scale_y_reverse(limits = c(1080 + de_mean, de_mean)) +
  geom_hline(yintercept = 0)
```

I tried a regular mixed model here. The good news is that the intercept - the average of Deaf Early - is nearly exactly what I calculated via averaging it myself (which was `r round(de_mean)`, off by just half a pixel!). It does not find a signfiicant difference for any group, which I guess is disappointing, then again the y-positions are not independent of one another so. Anyway! 

```{r message=FALSE, warning=FALSE}
library(lme4)
library(broom)

m <- lmer(y_ma5 ~ maingroup + (1|name), data = data)
tidy(m) %>%
  mutate_if(is.numeric, vars(round(.,2)))
```

## All 4 Stories

I'm going to try looking at all 4 FW stories together. Let's just do that. 

```{r message=FALSE, warning=FALSE}
library(glue)
# A lot of data loading here. 
files <- list.files("../Adult Data/rawdata/rawdataXLSX/", "fw") %>%
  paste0("../Adult Data/rawdata/rawdataXLSX/", .)

# Let's find out who was excluded for which stories
fw_excluded <- read_csv("finaldataset.csv") %>%
  filter(direction == "forward") %>%
  select(participant, maingroup, story, direction, eye_exclude) %>%
  rename(name = participant) %>%
  select(name, story, eye_exclude) %>%
  filter(eye_exclude)

# Alicia and Josh have double recordings of RedRidingHood, need to exclude
two_more_excluded <- tribble(
  ~name, ~recording_name,
  "Josh", "Rec 24",
  "Alicia", "Alicia_DontUseFirst_Good"
)

# Same as above...load, clean up names and groups, exclude
fw_data_raw <- map_dfr(files, read.xlsx) %>%
  clean_names() %>%
  rename(x = gaze_point_x_mc_spx,
         y = gaze_point_y_mc_spx,
         language = language_value,
         name = participant_name,
         group = group_value,
         story = media_name) %>%
  left_join(cleannames, by = "name") %>%
  select(-name) %>%
  rename(name = new_participant) %>%
  filter(!is.na(name)) %>%
  left_join(cleangroups, by = "name") %>%
  select(-group) %>%
  mutate(story = case_when(
    story == "Cindy_bears_FW_xvid.avi" ~ "Goldilocks",
    story == "midas_FW_xvid.avi" ~ "KingMidas",
    story == "Cindy_cinderella_FW_xvid.avi" ~ "Cinderella",
    story == "Cindy_redridinghood_FW_xvid.avi" ~ "RedRidingHood"
  )) %>%
  anti_join(fw_excluded, by = c("name", "story")) %>%
  anti_join(two_more_excluded, by = c("name", "recording_name")) %>%
  select(name, maingroup, story, gaze_point_index, x, y) %>%
  mutate_at(vars(name, maingroup, story), as.factor) %>%
  mutate_at(vars(gaze_point_index, x, y), as.integer)

skim(fw_data_raw)
```

Next, do moving average filtering and trim ends. How many missing data per participant now?

```{r}
trimming <- fw_data_raw %>% 
  group_by(story, maingroup) %>%
  summarise(max = max(gaze_point_index)) %>%
  ungroup() %>%
  group_by(story) %>%
  summarise(max = min(max) - 30) %>%
  add_column(min = 30)


# MA filter
fw_data <- fw_data_raw %>%
  as_tsibble(key = id(name, story), index = gaze_point_index) %>%
  group_by(name, story) %>%
  mutate(y_ma5 = slide_dbl(y, ~ mean(., na.rm = T), .size = 5),
         y_ma30 = slide_dbl(y, ~ mean(., na.rm = T), .size = 30)) %>%
  as_tibble() %>%
  ungroup() %>%
  left_join(trimming, by = c("story")) %>%
  filter(gaze_point_index > min & gaze_point_index < max) %>%
  select(-c(min, max))

fw_data %>%
  group_by(name, maingroup, story) %>%
  summarise_at(vars(y_ma5), funs(sum(is.na(.)))) %>%
  arrange(desc(y_ma5))

fw_data %>%
  group_by(maingroup, story) %>%
  summarise_at(vars(y_ma5), funs(sum(is.na(.)))) %>%
  arrange(desc(y_ma5)) %>%
  spread(story, y_ma5)
  
# fw_data %>%
#   ggplot(aes(x = maingroup, y = y_ma5, fill = maingroup)) +
#   geom_boxplot() +
#   facet_wrap("story") +
#   scale_y_reverse()
```

Now we're going to do baselines of Deaf Early for all 4 stories. 

```{r message=FALSE, warning=FALSE}
de_baselines <- fw_data %>%
  filter(maingroup == "DeafEarly") %>%
  group_by(story, gaze_point_index) %>%
  summarise(de_y_ma5 = mean(y_ma5, na.rm = T),
            de_y_ma30 = mean(y_ma30, na.rm = T))

individual_baselines <- fw_data %>%
  filter(maingroup != "DeafEarly") %>%
  left_join(de_baselines, by = c("story", "gaze_point_index")) %>%
  group_by(name, maingroup, story, gaze_point_index) %>%
  mutate(diff_y_ma5 = y_ma5 - de_y_ma5,
         diff_y_ma30 = y_ma30 - de_y_ma30)

individual_baselines %>%
  ggplot(aes(x = maingroup, y = diff_y_ma5, fill = maingroup)) +
  geom_violin() +
  geom_boxplot(width = 0.2, fill = "white") +
  scale_y_reverse(limits = c(1080 + de_mean, de_mean)) +
  geom_hline(yintercept = 0)

m <- lmer(y_ma5 ~ maingroup + (1|name), data = fw_data)
tidy(m) %>%
  mutate_if(is.numeric, vars(round(.,2)))

```

# Ridgeplots

Try ridgeplots. First I'll use the baselined data but that means we have to cut off all data below or above zero. 

```{r message=FALSE, warning=FALSE}
library(ggridges)
goldilocks_ridge <- fw_data %>%
  ungroup()

row_nums <- goldilocks_ridge %>%
  select(maingroup, story, name) %>%
  distinct() %>%
  group_by(maingroup, story) %>%
  arrange(maingroup, story, name) %>%
  ungroup() %>%
  mutate(rownum = row_number())

goldilocks_ridge <- goldilocks_ridge %>%
  left_join(row_nums, by = c("maingroup", "name", "story")) %>%
  mutate(name = fct_reorder(name, rownum))

ggplot(goldilocks_ridge) +
  aes(x = y, y = name, fill = maingroup) +
  geom_density_ridges() +
  facet_wrap("story", scales = "free")

goldilocks_ridge %>%
  filter(name != "Joe") %>%
  ggplot() +
  aes(x = y, y = maingroup, fill = maingroup) +
  geom_density_ridges() +
  facet_wrap("story")
```

# Aligning peaks and then finding local maxima

So we have good ridgeplots! We can then look at local maxima (small peaks) to see what was going on at that time of the video. But grouped ridgeplots mask individual differences so maybe we should align the peaks of a group first and then look again at the grouped ridgeplot? 

Let's try this first with an easy group - Deaf Early & Red Riding Hood

```{r}
easygroup <- fw_data %>%
  ungroup() %>%
  filter(story == "RedRidingHood")

easygroup %>%
  ggplot() +
  aes(x = y, y = name, fill = maingroup) +
  geom_density_ridges()
  

ggplot(easygroup) +
  aes(x = y, fill = name) +
  geom_histogram() +
  facet_wrap("name")
```

How to align one particiant's data based on the density peak.

```{r}
# https://ianmadd.github.io/pages/PeakDensityDistribution.html
michael <- easygroup %>%
  filter(name == "Michael") %>%
  drop_na() %>%
  mutate(y = y_ma30)

ggplot(michael) +
  geom_density(aes(x = y))

d <- density(michael$y)
which.max(d$y)
maxval <- d$x[which.max(d$y)]

michael <- michael %>%
  mutate(y2 = y + (400 - maxval))

ggplot(michael) +
  aes(x = y2) +
  geom_density()
```

I'm testing aligning all peaks onto the 400 px line. 

```{r}
testing <- easygroup %>%
  mutate(name = as.character(name)) %>%
  nest(-name) %>%
  mutate(density = map(data, ~ density(.$y, na.rm = T))) %>%
  mutate(max_y = map_int(density, ~ which.max(.$y))) %>%
  mutate(max_val = map2_dbl(density, max_y, ~ .x$x[[.y]])) %>%
  select(-density) %>%
  unnest() %>%
  mutate(y2 = y_ma30 + (400 - max_val))

ggplot(testing) +
  aes(x = y2, y = name, fill = maingroup) +
  geom_density_ridges()
```

So I won't align peaks. Let's just try to find local maxima. Let's use Mauro.

```{r}
mauro <- easygroup %>%
  filter(name == "Mauro")

to_hist <- density(mauro$y_ma30)$y

hist(to_hist)

ggplot(mauro, aes(x=y_ma30, y=1, fill=0.5 - abs(0.5-..ecdf..))) +
  stat_density_ridges(geom = "density_ridges_gradient", calc_ecdf = TRUE) +
  scale_fill_viridis(name = "Tail probability", direction = -1)

```

```{r}
# https://gist.github.com/ramhiser/5316385
find_peaks <- function(x, ...) {
  x <- as.vector(x)
  dens <- density(x, ..., na.rm = T)

  second_deriv <- diff(sign(diff(dens$y)))
  dens$x[which(second_deriv == -2) + 1]
}

vlines <- find_peaks(mauro$y_ma30)

ggplot(mauro, aes(x = y_ma30, y = 1)) +
  geom_density_ridges() +
  geom_vline(xintercept = vlines, alpha = 0.5)

last_peak = vlines[length(vlines)]
mauro %>%
  filter(y_ma30 <= last_peak + 10 & y_ma30 >= last_peak-10)
```

# Let's try umm. heartbeat area plots

```{r}
easygroup %>%
  filter(maingroup == "HearingNovice") %>%
  ggplot() +
  aes(x = gaze_point_index, y = y_ma30, fill = name, group = name) +
  geom_area() +
  scale_y_reverse() +
  facet_grid(name ~ .) +
  geom_vline(xintercept = 750) +
  geom_vline(xintercept = 1250)


# This is what I wanted instead! It’s just the heartbeat chart but this time it’s an area chart instead of a line chart. Easier to see downward shifts I think

# and there’s a shift down around 750 and 1300, that’s 6.25s and 10.83s respectively
```

